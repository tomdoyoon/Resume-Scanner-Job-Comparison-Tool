{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a1fd8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2962d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF file\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_file = PyPDF2.PdfReader(file_path)\n",
    "    text = ''\n",
    "    for page in range(len(pdf_file.pages)):\n",
    "        text += pdf_file.pages[page].extract_text()\n",
    "    return text\n",
    "\n",
    "# Pre-process the data\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Extract keywords from text\n",
    "def extract_keywords(text, ratio_threshold=80):\n",
    "    words = text.split()\n",
    "    keywords = []\n",
    "    for word in words:\n",
    "        if fuzz.token_set_ratio(word, text) >= ratio_threshold:\n",
    "            keywords.append(word)\n",
    "    return keywords\n",
    "\n",
    "# Replace resume.pdf with your resume\n",
    "resume_keywords = extract_keywords(preprocess_text(extract_text_from_pdf('resume.pdf')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b3bba079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# Define the job post URL\n",
    "url = 'https://www.linkedin.com/jobs/view/3455716295/?refId=d086dd12-f5e5-49c6-b79a-7df46fb86e70&trackingId=GFMyL8YCTJmGoBmgxVlaHA%3D%3D'\n",
    "\n",
    "# Send a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "\n",
    "# Find the script tag with the JSON-LD data\n",
    "job_post_script = soup.find('script', {'type': 'application/ld+json'})\n",
    "\n",
    "# Extract the text from the script tag and load it as JSON\n",
    "job_post_data = json.loads(job_post_script.text)\n",
    "\n",
    "# Extract the description from the JSON data\n",
    "job_post = job_post_data['description']\n",
    "\n",
    "job_post_text = preprocess_text(job_post)\n",
    "job_post_keywords = extract_keywords(job_post_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d326e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity score: 0.24723452927224\n",
      "Your resume is not a good match for the job post.\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between two keyword sets\n",
    "def calculate_cosine_similarity(keywords1, keywords2):\n",
    "    keywords1 = [word for word in keywords1 if len(word) >= 4]\n",
    "    keywords2 = [word for word in keywords2 if len(word) >= 4]\n",
    "    keywords1 = ' '.join(keywords1)\n",
    "    keywords2 = ' '.join(keywords2)\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform([keywords1, keywords2])\n",
    "    return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)[0][1]\n",
    "\n",
    "cosine_similarity_score = calculate_cosine_similarity(resume_keywords, job_post_keywords)\n",
    "\n",
    "print('Cosine similarity score:', cosine_similarity_score)\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "if cosine_similarity_score >= THRESHOLD:\n",
    "    print(\"Your resume is a good match for the job post.\")\n",
    "else:\n",
    "    print(\"Your resume is not a good match for the job post.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eaca68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_post_keywords_filtered = [word for word in job_post_keywords if len(word) >= 4]\n",
    "\n",
    "keyword_df = pd.DataFrame({'Job Post Keyword': job_post_keywords_filtered})\n",
    "keyword_df['Matched Resume Keyword'] = keyword_df['Job Post Keyword'].apply(lambda x: x if x in resume_keywords else float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fee9454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Post Keyword</th>\n",
       "      <th>Matched Resume Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scientist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>driven</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>company</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>improve</td>\n",
       "      <td>improve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>patient</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Job Post Keyword Matched Resume Keyword\n",
       "0             strong                    NaN\n",
       "1           clinical                    NaN\n",
       "2               data                   data\n",
       "3          scientist                    NaN\n",
       "4           clinical                    NaN\n",
       "..               ...                    ...\n",
       "923           driven                    NaN\n",
       "924          company                    NaN\n",
       "925          improve                improve\n",
       "926          patient                    NaN\n",
       "927             care                    NaN\n",
       "\n",
       "[928 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350051a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "924b08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "# Calculate levenshtein distance between two keyword sets\n",
    "def calculate_levenshtein_distance(keywords1, keywords2, threshold=0.75):\n",
    "    keywords1 = [word for word in keywords1 if len(word) >= 4]\n",
    "    keywords2 = [word for word in keywords2 if len(word) >= 4]\n",
    "    matching_keywords = []\n",
    "    for keyword1 in keywords1:\n",
    "        for keyword2 in keywords2:\n",
    "            distance = Levenshtein.distance(keyword1, keyword2)\n",
    "            length = max(len(keyword1), len(keyword2))\n",
    "            similarity = 1 - (distance / length)\n",
    "            if similarity >= threshold:\n",
    "                matching_keywords.append((keyword1, keyword2))\n",
    "    return matching_keywords\n",
    "\n",
    "matched_keywords = calculate_levenshtein_distance(resume_keywords, job_post_keywords)\n",
    "\n",
    "\n",
    "lev_match_df = pd.DataFrame(matched_keywords, columns=['Resume Keyword', 'Job Post Keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "448391b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resume Keyword</th>\n",
       "      <th>Job Post Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yoon</td>\n",
       "      <td>soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>certification</td>\n",
       "      <td>certification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>valuation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>valuation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>management</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>management</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Resume Keyword Job Post Keyword\n",
       "0             yoon             soon\n",
       "1           health           health\n",
       "2           health           health\n",
       "3           health           health\n",
       "4           health           health\n",
       "..             ...              ...\n",
       "745  certification    certification\n",
       "746      valuation       validation\n",
       "747      valuation       validation\n",
       "748     management       management\n",
       "749     management       management\n",
       "\n",
       "[750 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e972621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'clinical',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'clinical',\n",
       " 'informaticist',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'new',\n",
       " 'york',\n",
       " 'or',\n",
       " 'remote',\n",
       " 'full',\n",
       " 'time',\n",
       " 'early',\n",
       " 'to',\n",
       " 'mid',\n",
       " 'career',\n",
       " 'early',\n",
       " 'to',\n",
       " 'mid',\n",
       " 'start',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'resumes',\n",
       " 'questions',\n",
       " 'and',\n",
       " 'requests',\n",
       " 'for',\n",
       " 'assistance',\n",
       " 'or',\n",
       " 'an',\n",
       " 'accommodation',\n",
       " 'due',\n",
       " 'to',\n",
       " 'a',\n",
       " 'disability',\n",
       " 'may',\n",
       " 'be',\n",
       " 'directed',\n",
       " 'to',\n",
       " 'dandelion',\n",
       " 's',\n",
       " 'director',\n",
       " 'of',\n",
       " 'clinical',\n",
       " 'informatics',\n",
       " 'mara',\n",
       " 'dandelionhealth',\n",
       " 'ai',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'references',\n",
       " 'are',\n",
       " 'required',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'salary',\n",
       " 'range',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'k',\n",
       " 'k',\n",
       " 'equity',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'our',\n",
       " 'team',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'dandelion',\n",
       " 'health',\n",
       " 'was',\n",
       " 'founded',\n",
       " 'in',\n",
       " 'by',\n",
       " 'experts',\n",
       " 'in',\n",
       " 'health',\n",
       " 'tech',\n",
       " 'hospital',\n",
       " 'systems',\n",
       " 'academia',\n",
       " 'and',\n",
       " 'clinical',\n",
       " 'ai',\n",
       " 'we',\n",
       " 'are',\n",
       " 'building',\n",
       " 'the',\n",
       " 'world',\n",
       " 's',\n",
       " 'largest',\n",
       " 'ai',\n",
       " 'training',\n",
       " 'and',\n",
       " 'validation',\n",
       " 'platform',\n",
       " 'today',\n",
       " 'we',\n",
       " 'pride',\n",
       " 'ourselves',\n",
       " 'on',\n",
       " 'our',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'make',\n",
       " 'data',\n",
       " 'access',\n",
       " 'as',\n",
       " 'easy',\n",
       " 'as',\n",
       " 'possible',\n",
       " 'for',\n",
       " 'ai',\n",
       " 'developers',\n",
       " 'while',\n",
       " 'raising',\n",
       " 'the',\n",
       " 'bar',\n",
       " 'for',\n",
       " 'patient',\n",
       " 'safety',\n",
       " 'and',\n",
       " 'data',\n",
       " 'quality',\n",
       " 'tomorrow',\n",
       " 'we',\n",
       " 'will',\n",
       " 'be',\n",
       " 'the',\n",
       " 'place',\n",
       " 'where',\n",
       " 'any',\n",
       " 'ai',\n",
       " 'developer',\n",
       " 'can',\n",
       " 'go',\n",
       " 'to',\n",
       " 'build',\n",
       " 'a',\n",
       " 'responsible',\n",
       " 'clinical',\n",
       " 'ai',\n",
       " 'product',\n",
       " 'our',\n",
       " 'culture',\n",
       " 'is',\n",
       " 'all',\n",
       " 'about',\n",
       " 'learning',\n",
       " 'from',\n",
       " 'data',\n",
       " 'and',\n",
       " 'improving',\n",
       " 'so',\n",
       " 'we',\n",
       " 'can',\n",
       " 'help',\n",
       " 'our',\n",
       " 'clients',\n",
       " 'improve',\n",
       " 'health',\n",
       " 'through',\n",
       " 'ai',\n",
       " 'meet',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'our',\n",
       " 'team',\n",
       " 'here',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'our',\n",
       " 'data',\n",
       " 'and',\n",
       " 'cloud',\n",
       " 'stack',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'we',\n",
       " 'partner',\n",
       " 'with',\n",
       " 'health',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'safely',\n",
       " 'and',\n",
       " 'ethically',\n",
       " 'make',\n",
       " 'their',\n",
       " 'de',\n",
       " 'identified',\n",
       " 'patient',\n",
       " 'data',\n",
       " 'available',\n",
       " 'to',\n",
       " 'ai',\n",
       " 'developers',\n",
       " 'currently',\n",
       " 'the',\n",
       " 'data',\n",
       " 'is',\n",
       " 'acquired',\n",
       " 'from',\n",
       " 'sharp',\n",
       " 'healthcare',\n",
       " 'and',\n",
       " 'sanford',\n",
       " 'health',\n",
       " 'in',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'with',\n",
       " 'three',\n",
       " 'additional',\n",
       " 'u',\n",
       " 's',\n",
       " 'health',\n",
       " 'systems',\n",
       " 'joining',\n",
       " 'soon',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'we',\n",
       " 'have',\n",
       " 'clinical',\n",
       " 'data',\n",
       " 'dating',\n",
       " 'back',\n",
       " 'to',\n",
       " 'july',\n",
       " 'this',\n",
       " 'data',\n",
       " 'represents',\n",
       " 'over',\n",
       " 'million',\n",
       " 'patients',\n",
       " 'and',\n",
       " 'includes',\n",
       " 'but',\n",
       " 'is',\n",
       " 'not',\n",
       " 'limited',\n",
       " 'to',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'ul',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'structured',\n",
       " 'data',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'e',\n",
       " 'g',\n",
       " 'of',\n",
       " 'the',\n",
       " 'emr',\n",
       " 'including',\n",
       " 'some',\n",
       " 'claims',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'e',\n",
       " 'g',\n",
       " 'clinical',\n",
       " 'notes',\n",
       " 'radiology',\n",
       " 'reports',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'images',\n",
       " 'video',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'e',\n",
       " 'g',\n",
       " 'pacs',\n",
       " 'pathology',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'waveforms',\n",
       " 'streaming',\n",
       " 'inpatient',\n",
       " 'data',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'e',\n",
       " 'g',\n",
       " 'ecgs',\n",
       " 'icu',\n",
       " 'and',\n",
       " 'bed',\n",
       " 'monitors',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'ul',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'we',\n",
       " 'are',\n",
       " 'an',\n",
       " 'aws',\n",
       " 'and',\n",
       " 'python',\n",
       " 'shop',\n",
       " 'our',\n",
       " 'clients',\n",
       " 'partners',\n",
       " 'and',\n",
       " 'other',\n",
       " 'internal',\n",
       " 'teams',\n",
       " 'may',\n",
       " 'work',\n",
       " 'with',\n",
       " 'other',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'platforms',\n",
       " 'from',\n",
       " 'time',\n",
       " 'to',\n",
       " 'time',\n",
       " 'e',\n",
       " 'g',\n",
       " 'r',\n",
       " 'matlab',\n",
       " 'gcp',\n",
       " 'azure',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'your',\n",
       " 'role',\n",
       " 'lt',\n",
       " 'strong',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'you',\n",
       " 'are',\n",
       " 'a',\n",
       " 'residency',\n",
       " 'trained',\n",
       " 'physician',\n",
       " 'who',\n",
       " 'also',\n",
       " 'knows',\n",
       " 'your',\n",
       " 'way',\n",
       " 'around',\n",
       " 'electronic',\n",
       " 'health',\n",
       " 'record',\n",
       " 'data',\n",
       " 'and',\n",
       " 'can',\n",
       " 'code',\n",
       " 'your',\n",
       " 'primary',\n",
       " 'responsibility',\n",
       " 'is',\n",
       " 'to',\n",
       " 'create',\n",
       " 'ai',\n",
       " 'ready',\n",
       " 'datasets',\n",
       " 'for',\n",
       " 'our',\n",
       " 'clients',\n",
       " 'in',\n",
       " 'our',\n",
       " 'aws',\n",
       " 'environment',\n",
       " 'this',\n",
       " 'will',\n",
       " 'involve',\n",
       " 'working',\n",
       " 'across',\n",
       " 'the',\n",
       " 'organization',\n",
       " 'with',\n",
       " 'both',\n",
       " 'engineers',\n",
       " 'and',\n",
       " 'clinical',\n",
       " 'scientists',\n",
       " 'to',\n",
       " 'build',\n",
       " 'our',\n",
       " 'own',\n",
       " 'clean',\n",
       " 'reproducible',\n",
       " 'datasets',\n",
       " 'and',\n",
       " 'code',\n",
       " 'base',\n",
       " 'your',\n",
       " 'team',\n",
       " 's',\n",
       " 'ultimate',\n",
       " 'goal',\n",
       " 'is',\n",
       " 'to',\n",
       " 'deliver',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'quality',\n",
       " 'data',\n",
       " 'products',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'our',\n",
       " 'clients',\n",
       " 'who',\n",
       " 'are',\n",
       " 'ai',\n",
       " 'developers',\n",
       " 'building',\n",
       " 'products',\n",
       " 'that',\n",
       " 'improve',\n",
       " 'patient',\n",
       " 'health',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'you',\n",
       " 'bring',\n",
       " 'your',\n",
       " 'clinical',\n",
       " 'and',\n",
       " 'data',\n",
       " 'skill',\n",
       " 'sets',\n",
       " 'together',\n",
       " 'in',\n",
       " 'the',\n",
       " 'following',\n",
       " 'ways',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'ul',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'interacting',\n",
       " 'with',\n",
       " 'clients',\n",
       " 'ranging',\n",
       " 'from',\n",
       " 'ai',\n",
       " 'startups',\n",
       " 'to',\n",
       " 'established',\n",
       " 'life',\n",
       " 'sciences',\n",
       " 'companies',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'their',\n",
       " 'clinical',\n",
       " 'data',\n",
       " 'needs',\n",
       " 'and',\n",
       " 'translate',\n",
       " 'semantic',\n",
       " 'concepts',\n",
       " 'e',\n",
       " 'g',\n",
       " 'fatty',\n",
       " 'liver',\n",
       " 'disease',\n",
       " 'into',\n",
       " 'queries',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'executed',\n",
       " 'in',\n",
       " 'our',\n",
       " 'data',\n",
       " 'e',\n",
       " 'g',\n",
       " 'icd',\n",
       " 'code',\n",
       " 'ranges',\n",
       " 'regular',\n",
       " 'expression',\n",
       " 'matching',\n",
       " 'for',\n",
       " 'radiology',\n",
       " 'reports',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'querying',\n",
       " 'complex',\n",
       " 'source',\n",
       " 'systems',\n",
       " 'in',\n",
       " 'a',\n",
       " 'range',\n",
       " 'of',\n",
       " 'health',\n",
       " 'data',\n",
       " 'sources',\n",
       " 'e',\n",
       " 'g',\n",
       " 'emrs',\n",
       " 'ecg',\n",
       " 'data',\n",
       " 'dicom',\n",
       " 'data',\n",
       " 'to',\n",
       " 'create',\n",
       " 'high',\n",
       " 'quality',\n",
       " 'datasets',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'train',\n",
       " 'and',\n",
       " 'validate',\n",
       " 'ai',\n",
       " 'algorithms',\n",
       " 'you',\n",
       " 'have',\n",
       " 'extremely',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'attention',\n",
       " 'to',\n",
       " 'detail',\n",
       " 'but',\n",
       " 'also',\n",
       " 'know',\n",
       " 'how',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'big',\n",
       " 'picture',\n",
       " 'in',\n",
       " 'mind',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'working',\n",
       " 'with',\n",
       " 'non',\n",
       " 'medically',\n",
       " 'trained',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'as',\n",
       " 'they',\n",
       " 'help',\n",
       " 'create',\n",
       " 'and',\n",
       " 'validate',\n",
       " 'these',\n",
       " 'datasets',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'ul',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'afraid',\n",
       " 'to',\n",
       " 'dig',\n",
       " 'into',\n",
       " 'massive',\n",
       " 'confusing',\n",
       " 'disorganized',\n",
       " 'new',\n",
       " 'datasets',\n",
       " 'and',\n",
       " 'get',\n",
       " 'them',\n",
       " 'under',\n",
       " 'control',\n",
       " 'you',\n",
       " 'are',\n",
       " 'excited',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'new',\n",
       " 'environments',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'skills',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'small',\n",
       " 'early',\n",
       " 'stage',\n",
       " 'company',\n",
       " 'with',\n",
       " 'enormous',\n",
       " 'ambitions',\n",
       " 'and',\n",
       " 'everyone',\n",
       " 'pitches',\n",
       " 'in',\n",
       " 'to',\n",
       " 'do',\n",
       " 'everything',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'br',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'your',\n",
       " 'specific',\n",
       " 'responsibility',\n",
       " 'is',\n",
       " 'to',\n",
       " 'supervise',\n",
       " 'the',\n",
       " 'process',\n",
       " 'from',\n",
       " 'customer',\n",
       " 'request',\n",
       " 'to',\n",
       " 'dataset',\n",
       " 'delivery',\n",
       " 'this',\n",
       " 'will',\n",
       " 'include',\n",
       " 'the',\n",
       " 'following',\n",
       " 'amp',\n",
       " 'nbsp',\n",
       " 'lt',\n",
       " 'p',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'ul',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'perform',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'extraction',\n",
       " 'manipulation',\n",
       " 'and',\n",
       " 'summarization',\n",
       " 'of',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'data',\n",
       " 'to',\n",
       " 'create',\n",
       " 'analytical',\n",
       " 'datasets',\n",
       " 'and',\n",
       " 'provide',\n",
       " 'a',\n",
       " 'range',\n",
       " 'of',\n",
       " 'solutions',\n",
       " 'to',\n",
       " 'support',\n",
       " 'customers',\n",
       " 'ai',\n",
       " 'activities',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'support',\n",
       " 'the',\n",
       " 'design',\n",
       " 'testing',\n",
       " 'validation',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'merging',\n",
       " 'of',\n",
       " 'multimodal',\n",
       " 'data',\n",
       " 'structures',\n",
       " 'from',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'source',\n",
       " 'systems',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'support',\n",
       " 'all',\n",
       " 'phases',\n",
       " 'of',\n",
       " 'sql',\n",
       " 'analytical',\n",
       " 'programming',\n",
       " 'data',\n",
       " 'management',\n",
       " 'quality',\n",
       " 'control',\n",
       " 'and',\n",
       " 'reporting',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'li',\n",
       " 'gt',\n",
       " 'collaborate',\n",
       " 'with',\n",
       " 'customers',\n",
       " 'to',\n",
       " 'define',\n",
       " 'and',\n",
       " 'deliver',\n",
       " 'on',\n",
       " 'data',\n",
       " 'requests',\n",
       " 'with',\n",
       " 'accountability',\n",
       " 'for',\n",
       " 'timely',\n",
       " 'and',\n",
       " 'high',\n",
       " 'quality',\n",
       " 'delivery',\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_post_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6bf3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
