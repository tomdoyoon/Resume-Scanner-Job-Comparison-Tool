{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47b2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace resume.pdf with the file name of your resume\n",
    "resume='resume.pdf'\n",
    "# Define the job post URL\n",
    "url = 'https://www.linkedin.com/jobs/view/3580814554/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e978e7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.3971\n",
      "Your resume is not a good match for the job post.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "import pandas as pd\n",
    "from rake_nltk import Rake\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Extract text from PDF file\n",
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_file = PyPDF2.PdfReader(file_path)\n",
    "    text = ''\n",
    "    for page in range(len(pdf_file.pages)):\n",
    "        text += pdf_file.pages[page].extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    # remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # remove digits\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# Extract keywords from text\n",
    "def extract_keywords(text, ratio_threshold=80):\n",
    "    words = text.split()\n",
    "    keywords = []\n",
    "    for word in words:\n",
    "        if fuzz.token_set_ratio(word, text) >= ratio_threshold:\n",
    "            keywords.append(word)\n",
    "    return keywords\n",
    "\n",
    "##########################################################################\n",
    "resume_keywords = extract_keywords(preprocess_text(extract_text_from_pdf(resume)))\n",
    "##########################################################################\n",
    "\n",
    "# Send a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the script tag with the JSON-LD data\n",
    "job_post_script = soup.find('script', {'type': 'application/ld+json'})\n",
    "\n",
    "# Extract the text from the script tag and load it as JSON\n",
    "job_post_json = json.loads(job_post_script.text)\n",
    "\n",
    "# Extract the description text from the JSON\n",
    "job_post_desc = job_post_json.get('description', '')\n",
    "\n",
    "# Use BeautifulSoup to remove HTML tags from the description text\n",
    "job_post = BeautifulSoup(job_post_desc, 'html.parser').get_text()\n",
    "\n",
    "# Preprocess the job post description\n",
    "job_post = preprocess_text(job_post)\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(job_post)\n",
    "\n",
    "# Get the POS tags for each word\n",
    "pos_tags = pos_tag(words)\n",
    "\n",
    "# Define a list of POS tags that you want to include\n",
    "included_tags = ['NN', 'NNS', 'JJ', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "# Filter out the words that have POS tags that are not included\n",
    "keywords = [word for (word, tag) in pos_tags if tag in included_tags]\n",
    "\n",
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Print the keywords\n",
    "job_post_keywords = list(filter(lambda x: len(x) >= 5 and x not in stop, list(dict.fromkeys(keywords))))\n",
    "\n",
    "\n",
    "\n",
    "# Merge similar keywords\n",
    "merged_keywords = {}\n",
    "for keyword in job_post_keywords:\n",
    "    # Use fuzzy matching to find the most similar keyword\n",
    "    closest_match = process.extractOne(keyword, merged_keywords.keys(), scorer=fuzz.ratio)\n",
    "    if closest_match and closest_match[1] >= 90:\n",
    "        merged_keywords[closest_match[0]] += [keyword]\n",
    "    else:\n",
    "        merged_keywords[keyword] = [keyword]\n",
    "\n",
    "# Use the merged keywords as the final keyword list\n",
    "job_post_keywords = list(merged_keywords.keys())\n",
    "\n",
    "# Remove similar keywords\n",
    "final_keywords = []\n",
    "for i, keyword1 in enumerate(job_post_keywords):\n",
    "    # Check if keyword1 is too similar to any of the previous keywords\n",
    "    is_similar = False\n",
    "    for keyword2 in job_post_keywords[:i]:\n",
    "        # Calculate the Levenshtein distance between the two keywords\n",
    "        distance_score = levenshtein_distance(keyword1, keyword2)\n",
    "        # If the distance is below a certain threshold, consider the keywords too similar\n",
    "        if distance_score < 3:\n",
    "            is_similar = True\n",
    "            break\n",
    "    # If keyword1 is not too similar to any previous keywords, add it to the final keyword list\n",
    "    if not is_similar:\n",
    "        final_keywords.append(keyword1)\n",
    "\n",
    "job_post_keywords = final_keywords\n",
    "\n",
    "\n",
    "# Define the minimum threshold for the Levenshtein ratio\n",
    "levenshtein_threshold = .625\n",
    "# Create a list to store the matched keywords\n",
    "matched_keywords = []\n",
    "for x in range(len(job_post_keywords)):\n",
    "    max_ratio = 0\n",
    "    for y in range(len(resume_keywords)):\n",
    "        ratio = 1 - levenshtein_distance(job_post_keywords[x],resume_keywords[y]) / max(len(job_post_keywords[x]),len(resume_keywords[y]))\n",
    "        if ratio >= max_ratio:\n",
    "            max_ratio = ratio\n",
    "            best_match = resume_keywords[y]\n",
    "        else:\n",
    "            continue\n",
    "    if max_ratio >= levenshtein_threshold:\n",
    "        matched_keywords.append(best_match)\n",
    "    else:\n",
    "        matched_keywords.append('None')\n",
    "        \n",
    "\n",
    "job_phrases = Rake()\n",
    "job_phrases.extract_keywords_from_text(job_post)\n",
    "ranked_phrases = job_phrases.get_ranked_phrases()\n",
    "ranked_phrases = list(dict.fromkeys(ranked_phrases))\n",
    "ranked_phrases = [phrase for phrase in ranked_phrases if len(phrase.split()) > 1]\n",
    "\n",
    "# Create a list to store the matched keywords\n",
    "matched_keyphrases= []\n",
    "for x in range(len(ranked_phrases)):\n",
    "    phrase_words = ranked_phrases[x].split()\n",
    "    tally = 0\n",
    "    for y in range(len(phrase_words)):\n",
    "        for a in range(len(resume_keywords)):\n",
    "            ratio = 1 - levenshtein_distance(phrase_words[y],resume_keywords[a]) / max(len(phrase_words[y]),len(resume_keywords[a]))\n",
    "            if ratio >= levenshtein_threshold :\n",
    "                tally += 1\n",
    "                break\n",
    "    if tally >= len(phrase_words)/3:\n",
    "        matched_keyphrases.append(ranked_phrases[x])\n",
    "    else:\n",
    "        matched_keyphrases.append('None')\n",
    "##########################################################################\n",
    "# WEIGHT TO PHRASE\n",
    "weight_phrase = .65\n",
    "weight_word = 1-weight_phrase\n",
    "\n",
    "# PERCENTAGE SIMILAR SCORE\n",
    "sim_score = round((sum(x != 'None' for x in matched_keywords)/len(job_post_keywords)*weight_word) + (weight_phrase *sum(x != 'None' for x in matched_keyphrases)/len(ranked_phrases)),4)\n",
    "\n",
    "print('Similarity score:', sim_score)\n",
    "\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "if sim_score >= THRESHOLD:\n",
    "    print(\"Your resume is a good match for the job post.\")\n",
    "else:\n",
    "    print(\"Your resume is not a good match for the job post.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7bf918",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# RESULTS ANALYSIS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20353ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df = pd.DataFrame({'Job Post Keyword': job_post_keywords,'Matched Resume Keyword':matched_keywords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0624ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_df = pd.DataFrame({'Job Post Keyphrase': ranked_phrases,'Matched Resume Keyphrase':matched_keyphrases})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284bc88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
